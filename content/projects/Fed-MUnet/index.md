---
title: 'Fed-MUnet: Multi-modal Federated U-Net for Brain Tumor Segmentation at DKU'
summary: 'Privacy-preserving federated learning (FL) for multi-hospital MRI segmentation. A lightweight U-Net with a Cross-Modality Module (CMM) fuses T1/T1c/T2/FLAIR features; server-side clipped aggregation with calibrated noise stabilizes non-IID clients. On BraTS-style benchmarks, Fed-MUnet approaches centralized performance while keeping data on-prem.'
date: '2024-03-01'
image:
  focal_point: 'Smart'
  preview_only: false
---
üìÜ03/2024-08/2024
üë®‚Äçüè´Research Assistant to Professor Bing LuoÔºöAssistant Professor of Data and Computational Science	üìçKunshan, China

[Zhou, Ruojun, Lisha Qu, Lei Zhang, Ziming Li, Hongwei Yu, and Bing Luo. "Fed-MUnet: Multi-modal Federated Unet for Brain Tumor Segmentation." arXiv preprint arXiv:2409.01020 (2024).](./poster.pdf)



Privacy-preserving federated learning (FL) for multi-hospital MRI segmentation. A lightweight U-Net with a Cross-Modality Module (CMM) fuses T1/T1c/T2/FLAIR features; server-side clipped aggregation with calibrated noise stabilizes non-IID clients. On BraTS-style benchmarks, Fed-MUnet approaches centralized performance while keeping data on-prem.

Core ideas
	‚Ä¢	CMM fusion: transformer-style cross-attention aligns modalities to sharpen ET/TC/WT boundaries.
	‚Ä¢	Efficient backbone: depth-wise U-Net blocks balance accuracy and compute.
	‚Ä¢	Robust FL: flat-clipping + noise reduces client drift under heterogeneous data.

	‚Ä¢	Training paradigm (Fig. 1):
	‚Ä¢	Decentralized Training Paradigm for Brain Tumor Segmentation.
![Federated training rounds](images/fedmunet_paradigm.png "Client‚Äìserver FL for MRI segmentation")
	‚Ä¢	Model architecture with CMM (Fig. 2):
    Fig. 2: The framework of our segmentation backbone M-Unet. The right part is the structure of CMM. The overall framework follows the encoder-decoder architecture of Unet and a Transformer-like module CMM is used for multi-modal feature integration. For concatenation, we deploy a convolution operation to align the dimension of upsampling feature matrix
![Fed-MUnet + CMM](images/munet_cmm_arch.png "U-Net encoder‚Äìdecoder with cross-modal fusion")

	‚Ä¢	Qualitative results vs. ground truth (Fig. 3):
    Examples of Segmentation Results and Ground Truth. The area marked by the red circle is the difference between the true label and the inference result of the model with œÉ= 10^‚àí5
![BraTS samples: prediction vs label](images/brats_samples.png "ET/TC/WT overlays")


